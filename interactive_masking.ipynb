{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "interactive-masking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9RImQ7DV_8y"
      },
      "source": [
        "# Latent Composition Interactive Masking\n",
        "\n",
        "Demonstrates using a masked encoder to investigate image priors in GANs.\n",
        "\n",
        "Related Colab Notebooks:\n",
        "- [Interactive Composition Demo](https://colab.research.google.com/drive/1j7Bz9vdVnxzOgokawA39hCJZLTmVDq6_?usp=sharing): Interface to compose multiple images using masked encoder.\n",
        "- [Finetune and Edit](https://colab.research.google.com/drive/1zpD_UYqiGqjzftYxHQPy4sxOQTWV_QY9?usp=sharing): For real images, finetune the encoder towards a specific image for better reconstruction. Further composition can be done in real time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4acfzEryWPHN"
      },
      "source": [
        "## Download code, models, and set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpHfeuJ2UUyo",
        "outputId": "92eec2c4-c39a-49a7-95ad-cffe243a9b62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! git clone https://github.com/chail/latent-composition.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'latent-composition'...\n",
            "remote: Enumerating objects: 318, done.\u001b[K\n",
            "remote: Counting objects: 100% (318/318), done.\u001b[K\n",
            "remote: Compressing objects: 100% (237/237), done.\u001b[K\n",
            "remote: Total 318 (delta 146), reused 217 (delta 73), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (318/318), 7.81 MiB | 14.77 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7rkPtzqWyA5"
      },
      "source": [
        "import os\n",
        "os.chdir('latent-composition')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNp2HAmrdNaG",
        "outputId": "ae27b543-7888-4707-83e7-461f0ca24228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# required for stylegan models\n",
        "! pip install ninja"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 2.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0fpBwrdUCNo"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from utils import show, renormalize, pbar\n",
        "from utils import util, paintwidget, labwidget, imutil\n",
        "from networks import networks\n",
        "from PIL import Image\n",
        "import os\n",
        "from torchvision import transforms\n",
        "import time"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRDFgZRyewWf"
      },
      "source": [
        "os.environ['TORCH_EXTENSIONS_DIR'] = '/tmp/torch_cpp/' # needed for stylegan to run"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l92dBAljhNTk"
      },
      "source": [
        "assert(torch.cuda.is_available()) # check cuda is available"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYA1NOa8U0It"
      },
      "source": [
        "# Load Networks\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_hJD3JyUyby"
      },
      "source": [
        "#@title Select a model from the dropdown menu\n",
        "\n",
        "dropdown = 'stylegan car' #@param [\"stylegan car\", \"stylegan church\", \"stylegan horse\", \"stylegan ffhq\", \"proggan celebahq\", \"proggan church\", \"proggan livingroom\"]\n",
        "\n",
        "model_type, domain = dropdown.split()\n",
        "nets = networks.define_nets(model_type, domain)\n",
        "outdim = nets.setting['outdim']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQCZMZ2oVA2e"
      },
      "source": [
        "# Sample an image, and reencode it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnKBMrI-UuQT"
      },
      "source": [
        "#@title Select the input image.\n",
        "\n",
        "#@markdown Select a random seed to generate an image.\n",
        "random_seed = 0 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "\n",
        "#@markdown Uncheck this box if you want to use a real image instead.\n",
        "use_g_sample = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if use_g_sample:\n",
        "    # use a gan image as source\n",
        "    with torch.no_grad():\n",
        "        source_z = nets.sample_zs(1, seed=random_seed)\n",
        "        source_im = nets.zs2image(source_z)\n",
        "    show(['Source Image', renormalize.as_image(source_im[0]).resize((256, 256), Image.LANCZOS)])\n",
        "else:\n",
        "    # use a real image as source \n",
        "    if domain != \"car\":\n",
        "      print(\"!! WARNING !!: The default image is a car, please use the stylegan_car model or change im_path.\")\n",
        "    im_path = 'img/car0.png' # 'img/car1.png'\n",
        "    transform = transforms.Compose([\n",
        "                    transforms.Resize(outdim),\n",
        "                    transforms.CenterCrop(outdim),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                ])    \n",
        "    source_im = transform(Image.open(im_path))[None].cuda()\n",
        "    show(['Source Image', renormalize.as_image(source_im[0]).resize((256, 256), Image.LANCZOS)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gukRq6zqU9kF"
      },
      "source": [
        "with torch.no_grad():\n",
        "    out = nets.invert(source_im)\n",
        "    show(['Inverted Image', renormalize.as_image(out[0]).resize((256, 256), Image.LANCZOS)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOdgQ5nrVHTq"
      },
      "source": [
        "# Visualize network priors\n",
        "Drag your mouse on the left panel, and the GAN reconstruction will show in the right panel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrMHd9jwVMpq"
      },
      "source": [
        "src_painter = paintwidget.PaintWidget(oneshot=False, width=256, height=256, \n",
        "                                      brushsize=20, save_sequence=False, track_move=True) # , on_move=True)\n",
        "src_painter.image = renormalize.as_url(source_im[0], size=256)\n",
        "\n",
        "img_url = renormalize.as_url(torch.zeros(3, 256, 256))\n",
        "img_html = '<img src=\"%s\"/>'%img_url\n",
        "output_div = labwidget.Div(img_html)\n",
        "\n",
        "counter = 0\n",
        "prev_time = time.time()\n",
        "update_freq = 0.5 # mouse time intervals;  \n",
        "# decrease update_freq to reduce lagging, but colab is kind of slow\n",
        "mask_list = []\n",
        "reconstruction_list = []\n",
        "\n",
        "def probe_changed(c):\n",
        "    global counter\n",
        "    global prev_time\n",
        "    counter += 1\n",
        "    curr_time = time.time()\n",
        "    if curr_time - prev_time < update_freq:\n",
        "        return\n",
        "    prev_time = time.time()\n",
        "    \n",
        "    mask_url = src_painter.mask_buffer\n",
        "    mask =  renormalize.from_url(mask_url, target='pt', size=(outdim, outdim)).cuda()[None] # 1x3xHxW\n",
        "    with torch.no_grad():\n",
        "        mask = mask[:, [0], :, :] # 1x1xHxW\n",
        "        mask_list.append(mask.cpu())\n",
        "        masked_im = source_im * mask\n",
        "        regenerated_mask = nets.invert(masked_im, mask)\n",
        "    img_url = renormalize.as_url(regenerated_mask[0], size=256)\n",
        "    img_html = '<img src=\"%s\"/>'%img_url\n",
        "    output_div.innerHTML = img_html\n",
        "    reconstruction_list.append(renormalize.as_image(regenerated_mask[0]))\n",
        "    \n",
        "src_painter.on('mask_buffer', probe_changed)\n",
        "\n",
        "show.a([src_painter], cols=2)\n",
        "show.a([output_div], cols=2)\n",
        "\n",
        "show.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwZJkcNUgpjl"
      },
      "source": [
        "if len(mask_list) > 1:\n",
        "  show.a(['Masked Input', renormalize.as_image((mask_list[-1] * source_im.cpu())[0]).resize((256, 256), Image.ANTIALIAS)])\n",
        "  show.a(['Reconstruction', reconstruction_list[-1].resize((256,256), Image.ANTIALIAS)])\n",
        "  show.flush()\n",
        "else:\n",
        "  print(\"Drag the mouse on the left panel to visualize the result.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}