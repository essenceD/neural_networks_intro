{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Постройте нейронную сеть (берем несложную полносвязную сеть, меняем число слоев, число нейронов, типы активации, тип оптимизатора) на датасете from sklearn.datasets import load_boston. \n",
    "2. Постройте 10-15 вариантов разных нейронных сетей и сведите результаты их работы в таблицу.  Опишите, какого результата вы добились от нейросети? Что помогло вам улучшить ее точность?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNetCompare:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 X,\n",
    "                 y,\n",
    "                 epoch_list=[10],\n",
    "                 neuron_list=[32],\n",
    "                 layer_list=[2],\n",
    "                 activator_list=['sigmoid'],\n",
    "                 optimizer_list=['Adam'],\n",
    "                 mix=False                \n",
    "                ):\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.e_list = epoch_list\n",
    "        self.n_list = neuron_list\n",
    "        self.l_list = layer_list\n",
    "        self.act_list = activator_list\n",
    "        self.opt_list = optimizer_list\n",
    "        self.mix = mix\n",
    "                \n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        tf.random.set_seed(42)\n",
    "        \n",
    "        result = pd.DataFrame(columns=['n_layers',\n",
    "                                       'n_neurons',\n",
    "                                       'activator',\n",
    "                                       'optimizer', \n",
    "                                       'n_epoch',\n",
    "                                       'loss_train',\n",
    "                                       'r2_score_train',\n",
    "                                       'loss_test', \n",
    "                                       'r2_score_test'\n",
    "                                      ])\n",
    "        if not self.mix:\n",
    "            for epoch in self.e_list:\n",
    "                for layers in self.l_list:\n",
    "                    for neurons in self.n_list:\n",
    "                        for activator in self.act_list:\n",
    "                            for optimizer in self.opt_list:\n",
    "\n",
    "                                model_data = self.build_net(layers,\n",
    "                                                            neurons,\n",
    "                                                            activator,\n",
    "                                                           )\n",
    "                                model, act_list = model_data\n",
    "\n",
    "                                with tf.device(\"GPU:0\"):\n",
    "                                    model.compile(loss='mean_squared_error',\n",
    "                                                  optimizer=optimizer, \n",
    "                                                  metrics=tf.keras.metrics.RootMeanSquaredError()\n",
    "                                                 )\n",
    "\n",
    "                                with tf.device(\"GPU:0\"):\n",
    "                                    history = self.fit(model, epoch)\n",
    "\n",
    "                                result = result.append({'n_layers': layers,\n",
    "                                                        'n_neurons': neurons,\n",
    "                                                        'activator': '->'.join(act_list),\n",
    "                                                        'optimizer': optimizer, \n",
    "                                                        'n_epoch': len(history.history['loss']),\n",
    "                                                        'loss_train': history.history['loss'][-1],\n",
    "                                                        'r2_score_train': history.history['root_mean_squared_error'][-1],\n",
    "                                                        'loss_test': history.history['val_loss'][-1], \n",
    "                                                        'r2_score_test': history.history['val_root_mean_squared_error'][-1]\n",
    "                                                       }, ignore_index=True)\n",
    "        else:\n",
    "            \n",
    "            for epoch in self.e_list:\n",
    "                for layers in self.l_list:\n",
    "                    for neurons in self.n_list:\n",
    "\n",
    "                        model_data = self.build_net(layers,\n",
    "                                                    neurons,\n",
    "                                                    activator='fake', # это, конечно, костыль, но не хочется переписывать функцию self.build_net(). Извините =)\n",
    "                                                   )\n",
    "                        model, act_list = model_data\n",
    "                        \n",
    "                        optimizer = np.random.choice(self.opt_list)\n",
    "\n",
    "                        with tf.device(\"GPU:0\"):\n",
    "                            model.compile(loss='mean_squared_error',\n",
    "                                          optimizer=optimizer, \n",
    "                                          metrics=tf.keras.metrics.RootMeanSquaredError()\n",
    "                                         )\n",
    "\n",
    "                        with tf.device(\"GPU:0\"):\n",
    "                            history = self.fit(model, epoch)\n",
    "\n",
    "                        result = result.append({'n_layers': layers,\n",
    "                                                'n_neurons': neurons,\n",
    "                                                'activator': '->'.join(act_list),\n",
    "                                                'optimizer': optimizer, \n",
    "                                                'n_epoch': len(history.history['loss']),\n",
    "                                                'loss_train': history.history['loss'][-1],\n",
    "                                                'r2_score_train': history.history['root_mean_squared_error'][-1],\n",
    "                                                'loss_test': history.history['val_loss'][-1], \n",
    "                                                'r2_score_test': history.history['val_root_mean_squared_error'][-1]\n",
    "                                               }, ignore_index=True)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "                \n",
    "    def fit(self, \n",
    "            model,\n",
    "            epochs,\n",
    "           ):\n",
    "        \n",
    "        hist = model.fit(self.X,\n",
    "                         self.y,\n",
    "                         epochs=epochs,\n",
    "                         batch_size=520, \n",
    "                         verbose=0,\n",
    "                         validation_split=0.3\n",
    "                        )\n",
    "        \n",
    "        return hist\n",
    "    \n",
    "           \n",
    "    def build_net(self,\n",
    "                  n_layers,\n",
    "                  n_neurons,                   \n",
    "                  activator,\n",
    "                 ):\n",
    "        \n",
    "        act_list = []\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        # input_act = np.random.choice(['linear', 'relu'])\n",
    "        act_list.append('relu')\n",
    "        \n",
    "        model.add(Dense(self.X.shape[1],\n",
    "                        input_shape=(self.X.shape[1],), \n",
    "                        activation='relu'))\n",
    "        \n",
    "        delta = n_neurons // (n_layers + 1)\n",
    "        next_neurons = n_neurons\n",
    "        \n",
    "        tf.random.set_seed(42)\n",
    "        \n",
    "        for layer in range(n_layers):\n",
    "            if not self.mix:\n",
    "                model.add(Dense(next_neurons, activator))\n",
    "                act_list.append(activator)\n",
    "            else:\n",
    "                next_act = np.random.choice(self.act_list)\n",
    "                model.add(Dense(next_neurons, next_act))\n",
    "                act_list.append(next_act)\n",
    "            next_neurons -= delta\n",
    "        \n",
    "        model.add(Dense(1, 'linear'))\n",
    "        act_list.append('linear')\n",
    "        \n",
    "        return [model, act_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "data = pd.DataFrame(boston['data'], columns=boston[\"feature_names\"])\n",
    "target = boston[\"target\"]\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 51.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = NNetCompare(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_layers</th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>activator</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>n_epoch</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>r2_score_train</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>r2_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>relu-&gt;sigmoid-&gt;sigmoid-&gt;linear</td>\n",
       "      <td>Adam</td>\n",
       "      <td>10</td>\n",
       "      <td>718.300781</td>\n",
       "      <td>26.801134</td>\n",
       "      <td>356.774872</td>\n",
       "      <td>18.888485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_layers n_neurons                       activator optimizer n_epoch  \\\n",
       "0        2        32  relu->sigmoid->sigmoid->linear      Adam      10   \n",
       "\n",
       "   loss_train r2_score_train   loss_test r2_score_test  \n",
       "0  718.300781      26.801134  356.774872     18.888485  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sample.run()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [6, 9, 12]\n",
    "layers = [2, 3, 4]\n",
    "activators = ['softmax', 'linear', 'relu']\n",
    "optimizer = ['Adam', 'RMSProp']\n",
    "epoch = [10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_2 = NNetCompare(data,\n",
    "                       target,\n",
    "                       epoch_list=epoch,\n",
    "                       neuron_list=neurons,\n",
    "                       layer_list=layers,\n",
    "                       activator_list=activators,\n",
    "                       optimizer_list=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_layers</th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>activator</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>n_epoch</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>r2_score_train</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>r2_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>relu-&gt;relu-&gt;relu-&gt;relu-&gt;relu-&gt;linear</td>\n",
       "      <td>RMSProp</td>\n",
       "      <td>20</td>\n",
       "      <td>55.812748</td>\n",
       "      <td>7.470793</td>\n",
       "      <td>165.823975</td>\n",
       "      <td>12.877266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>relu-&gt;relu-&gt;relu-&gt;relu-&gt;relu-&gt;linear</td>\n",
       "      <td>RMSProp</td>\n",
       "      <td>10</td>\n",
       "      <td>58.409744</td>\n",
       "      <td>7.642627</td>\n",
       "      <td>180.320465</td>\n",
       "      <td>13.428346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>relu-&gt;relu-&gt;relu-&gt;relu-&gt;relu-&gt;linear</td>\n",
       "      <td>Adam</td>\n",
       "      <td>20</td>\n",
       "      <td>61.446251</td>\n",
       "      <td>7.838766</td>\n",
       "      <td>163.160751</td>\n",
       "      <td>12.773439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>relu-&gt;relu-&gt;relu-&gt;relu-&gt;relu-&gt;linear</td>\n",
       "      <td>RMSProp</td>\n",
       "      <td>20</td>\n",
       "      <td>64.021675</td>\n",
       "      <td>8.001354</td>\n",
       "      <td>236.264038</td>\n",
       "      <td>15.370883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>relu-&gt;relu-&gt;relu-&gt;relu-&gt;relu-&gt;linear</td>\n",
       "      <td>RMSProp</td>\n",
       "      <td>20</td>\n",
       "      <td>64.831184</td>\n",
       "      <td>8.051782</td>\n",
       "      <td>209.918381</td>\n",
       "      <td>14.488561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_layers n_neurons                             activator optimizer  \\\n",
       "95         4         6  relu->relu->relu->relu->relu->linear   RMSProp   \n",
       "41         4         6  relu->relu->relu->relu->relu->linear   RMSProp   \n",
       "94         4         6  relu->relu->relu->relu->relu->linear      Adam   \n",
       "107        4        12  relu->relu->relu->relu->relu->linear   RMSProp   \n",
       "101        4         9  relu->relu->relu->relu->relu->linear   RMSProp   \n",
       "\n",
       "    n_epoch loss_train r2_score_train   loss_test r2_score_test  \n",
       "95       20  55.812748       7.470793  165.823975     12.877266  \n",
       "41       10  58.409744       7.642627  180.320465     13.428346  \n",
       "94       20  61.446251       7.838766  163.160751     12.773439  \n",
       "107      20  64.021675       8.001354  236.264038     15.370883  \n",
       "101      20  64.831184       8.051782  209.918381     14.488561  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_2 = sample_2.run()\n",
    "res_2.sort_values(by='r2_score_test', ascending=False).head(5)\n",
    "# res_2.sort_values(by='loss_train', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [25, 35, 45]\n",
    "layers = [2, 3]\n",
    "activators = ['linear', 'relu']\n",
    "optimizer = ['Adam', 'RMSProp']\n",
    "epoch = [7, 10, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_3 = NNetCompare(data,\n",
    "                       target,\n",
    "                       epoch_list=epoch,\n",
    "                       neuron_list=neurons,\n",
    "                       layer_list=layers,\n",
    "                       activator_list=activators,\n",
    "                       optimizer_list=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_layers</th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>activator</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>n_epoch</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>r2_score_train</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>r2_score_test</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>relu-&gt;relu-&gt;relu-&gt;relu-&gt;linear</td>\n",
       "      <td>Adam</td>\n",
       "      <td>7</td>\n",
       "      <td>141.358383</td>\n",
       "      <td>11.889423</td>\n",
       "      <td>113.317795</td>\n",
       "      <td>10.645083</td>\n",
       "      <td>1.24434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>relu-&gt;linear-&gt;linear-&gt;linear-&gt;linear</td>\n",
       "      <td>RMSProp</td>\n",
       "      <td>10</td>\n",
       "      <td>125.271019</td>\n",
       "      <td>11.192453</td>\n",
       "      <td>97.689041</td>\n",
       "      <td>9.883777</td>\n",
       "      <td>1.308677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>relu-&gt;linear-&gt;linear-&gt;linear-&gt;linear</td>\n",
       "      <td>Adam</td>\n",
       "      <td>7</td>\n",
       "      <td>694.53125</td>\n",
       "      <td>26.353962</td>\n",
       "      <td>586.356201</td>\n",
       "      <td>24.214792</td>\n",
       "      <td>2.13917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>relu-&gt;relu-&gt;relu-&gt;linear</td>\n",
       "      <td>Adam</td>\n",
       "      <td>7</td>\n",
       "      <td>8963.314453</td>\n",
       "      <td>94.674782</td>\n",
       "      <td>8505.273438</td>\n",
       "      <td>92.224037</td>\n",
       "      <td>2.450745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>relu-&gt;linear-&gt;linear-&gt;linear-&gt;linear</td>\n",
       "      <td>RMSProp</td>\n",
       "      <td>7</td>\n",
       "      <td>163.407791</td>\n",
       "      <td>12.783106</td>\n",
       "      <td>235.827118</td>\n",
       "      <td>15.356664</td>\n",
       "      <td>2.573558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_layers n_neurons                             activator optimizer n_epoch  \\\n",
       "22        3        45        relu->relu->relu->relu->linear      Adam       7   \n",
       "45        3        45  relu->linear->linear->linear->linear   RMSProp      10   \n",
       "12        3        25  relu->linear->linear->linear->linear      Adam       7   \n",
       "6         2        35              relu->relu->relu->linear      Adam       7   \n",
       "21        3        45  relu->linear->linear->linear->linear   RMSProp       7   \n",
       "\n",
       "     loss_train r2_score_train    loss_test r2_score_test      diff  \n",
       "22   141.358383      11.889423   113.317795     10.645083   1.24434  \n",
       "45   125.271019      11.192453    97.689041      9.883777  1.308677  \n",
       "12    694.53125      26.353962   586.356201     24.214792   2.13917  \n",
       "6   8963.314453      94.674782  8505.273438     92.224037  2.450745  \n",
       "21   163.407791      12.783106   235.827118     15.356664  2.573558  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_3 = sample_3.run()\n",
    "res_3.sort_values(by='r2_score_test', ascending=False).head(5)\n",
    "# res_3['diff'] = abs(res_3['r2_score_test'] - res_3['r2_score_train'])\n",
    "# res_3.sort_values(by='diff', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample31 = NNetCompare(data,\n",
    "                       target,\n",
    "                       epoch_list=[500],\n",
    "                       neuron_list=[35],\n",
    "                       layer_list=[3],\n",
    "                       activator_list=['relu'],\n",
    "                       optimizer_list=['Adam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_layers</th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>activator</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>n_epoch</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>r2_score_train</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>r2_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>relu-&gt;relu-&gt;relu-&gt;relu-&gt;linear</td>\n",
       "      <td>Adam</td>\n",
       "      <td>500</td>\n",
       "      <td>17.270987</td>\n",
       "      <td>4.155838</td>\n",
       "      <td>843.381714</td>\n",
       "      <td>29.041035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_layers n_neurons                       activator optimizer n_epoch  \\\n",
       "0        3        35  relu->relu->relu->relu->linear      Adam     500   \n",
       "\n",
       "  loss_train r2_score_train   loss_test r2_score_test  \n",
       "0  17.270987       4.155838  843.381714     29.041035  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res31 = sample31.run()\n",
    "res31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [75, 120]\n",
    "layers = [3, 4]\n",
    "activators = ['relu', 'linear']\n",
    "optimizer = ['Adam', 'RMSProp']\n",
    "epoch = [9, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_4 = NNetCompare(data,\n",
    "                       target,\n",
    "                       epoch_list=epoch,\n",
    "                       neuron_list=neurons,\n",
    "                       layer_list=layers,\n",
    "                       activator_list=activators,\n",
    "                       optimizer_list=optimizer, \n",
    "                       mix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_layers</th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>activator</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>n_epoch</th>\n",
       "      <th>loss_train</th>\n",
       "      <th>r2_score_train</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>r2_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>relu-&gt;relu-&gt;relu-&gt;linear-&gt;linear-&gt;linear</td>\n",
       "      <td>Adam</td>\n",
       "      <td>9</td>\n",
       "      <td>451.886688</td>\n",
       "      <td>21.257626</td>\n",
       "      <td>1146.239868</td>\n",
       "      <td>33.856163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>relu-&gt;linear-&gt;linear-&gt;linear-&gt;linear</td>\n",
       "      <td>Adam</td>\n",
       "      <td>12</td>\n",
       "      <td>82.674164</td>\n",
       "      <td>9.092533</td>\n",
       "      <td>394.421295</td>\n",
       "      <td>19.860043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>relu-&gt;relu-&gt;relu-&gt;relu-&gt;linear</td>\n",
       "      <td>RMSProp</td>\n",
       "      <td>12</td>\n",
       "      <td>67.799446</td>\n",
       "      <td>8.234042</td>\n",
       "      <td>331.236328</td>\n",
       "      <td>18.1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>relu-&gt;relu-&gt;linear-&gt;linear-&gt;linear</td>\n",
       "      <td>Adam</td>\n",
       "      <td>9</td>\n",
       "      <td>284.254028</td>\n",
       "      <td>16.859835</td>\n",
       "      <td>217.741501</td>\n",
       "      <td>14.756066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>relu-&gt;linear-&gt;linear-&gt;linear-&gt;relu-&gt;linear</td>\n",
       "      <td>RMSProp</td>\n",
       "      <td>12</td>\n",
       "      <td>62.64883</td>\n",
       "      <td>7.915102</td>\n",
       "      <td>141.870224</td>\n",
       "      <td>11.910929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_layers n_neurons                                   activator optimizer  \\\n",
       "2        4        75    relu->relu->relu->linear->linear->linear      Adam   \n",
       "4        3        75        relu->linear->linear->linear->linear      Adam   \n",
       "5        3       120              relu->relu->relu->relu->linear   RMSProp   \n",
       "1        3       120          relu->relu->linear->linear->linear      Adam   \n",
       "6        4        75  relu->linear->linear->linear->relu->linear   RMSProp   \n",
       "\n",
       "  n_epoch  loss_train r2_score_train    loss_test r2_score_test  \n",
       "2       9  451.886688      21.257626  1146.239868     33.856163  \n",
       "4      12   82.674164       9.092533   394.421295     19.860043  \n",
       "5      12   67.799446       8.234042   331.236328       18.1999  \n",
       "1       9  284.254028      16.859835   217.741501     14.756066  \n",
       "6      12    62.64883       7.915102   141.870224     11.910929  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_4 = sample_4.run()\n",
    "res_4.sort_values(by='r2_score_test', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мне почему-то не удалось достигнуть стабильного адекватного значения метрики. Напишите, пожалуйста, в комментариях к ДЗ что не так у меня. Я переделаю правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
